{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sales_train.csv')\n",
    "items = pd.read_csv('items.csv')\n",
    "items = items.drop('item_name', axis=1)\n",
    "test  = pd.read_csv('test.csv').set_index('ID')\n",
    "test['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "date: 01.01.2013 ~ 31.12.2014\n",
      "date_block_num: 0 ~ 33\n",
      "shop_id: 0 ~ 59\n",
      "item_id: 0 ~ 22169\n",
      "item_price: -1.0 ~ 307980.0\n",
      "item_cnt_day: -22.0 ~ 2169.0\n",
      "items:\n",
      "item_id: 0 ~ 22169\n",
      "item_category_id: 0 ~ 83\n",
      "test:\n",
      "shop_id: 2 ~ 59\n",
      "item_id: 30 ~ 22167\n",
      "date_block_num: 34 ~ 34\n"
     ]
    }
   ],
   "source": [
    "# Compress data size, get the ranges of each feature to select the most appropriate data size\n",
    "print ('train:')\n",
    "for f in train.columns.values:\n",
    "    print ('%s: %s ~ %s' %(f, train[f].min(), train[f].max()))\n",
    "print ('items:')\n",
    "for f in items.columns.values:\n",
    "    print ('%s: %s ~ %s' %(f, items[f].min(), items[f].max()))\n",
    "print ('test:')\n",
    "for f in test.columns.values:\n",
    "    print ('%s: %s ~ %s' %(f, test[f].min(), test[f].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_col(df,columns,keyword,search_type,datatype):\n",
    "    if search_type=='in':\n",
    "        valid_features = [x for x in columns if keyword in x]\n",
    "    elif search_type=='start':\n",
    "        valid_features = [x for x in columns if x.startswith(keyword)]\n",
    "    if len(valid_features):\n",
    "        for f in valid_features:\n",
    "            df[f] = df[f].round().astype(datatype)\n",
    "    return df\n",
    "\n",
    "# Original-features\n",
    "def data_compression(df):\n",
    "    features = df.columns.values\n",
    "    if 'date_block_num' in features:\n",
    "        df['date_block_num'] = df['date_block_num'].astype(np.int8)\n",
    "    if 'shop_id' in features:\n",
    "        df['shop_id'] = df['shop_id'].astype(np.int8)\n",
    "    if 'item_category_id' in features:\n",
    "        df['item_category_id'] = df['item_category_id'].astype(np.int8)\n",
    "    if 'item_id' in features:\n",
    "        df['item_id'] = df['item_id'].astype(np.int16)\n",
    "    if 'item_price' in features:\n",
    "        df['item_price'] = df['item_price'].astype(np.float32)\n",
    "    if 'item_id_avg_item_price' in features:\n",
    "        df['item_id_avg_item_price'] = df['item_id_avg_item_price'].astype(np.float32)\n",
    "        \n",
    "    # Mean encoded features & lag features\n",
    "    df = compress_col(df,features,'item_id_sum_item_cnt_day','in',np.int16)\n",
    "    df = compress_col(df,features,'item_id_avg_item_cnt_day','in',np.float16)\n",
    "    \n",
    "    df = compress_col(df,features,'shop_id_avg_item_price','in',np.float16)\n",
    "    df = compress_col(df,features,'shop_id_sum_item_cnt_day','in',np.int16)\n",
    "    df = compress_col(df,features,'shop_id_avg_item_cnt_day','in',np.float16)\n",
    "    \n",
    "    df = compress_col(df,features,'item_category_id_avg_item_price','in',np.float16)\n",
    "    df = compress_col(df,features,'item_category_id_sum_item_cnt_day','in',np.int32)\n",
    "    df = compress_col(df,features,'item_category_id_avg_item_cnt_day','in',np.float16)\n",
    "    \n",
    "    df = compress_col(df,features,'item_cnt_day','start',np.int16)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress features\n",
    "train = data_compression(train)\n",
    "items = data_compression(items)\n",
    "test = data_compression(test)\n",
    "# Include Category_id\n",
    "train = pd.merge(train,items,on='item_id',how='left')\n",
    "test = pd.merge(test,items, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge duplicated shops\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2935849 entries, 0 to 2935848\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   date              object \n",
      " 1   date_block_num    int8   \n",
      " 2   shop_id           int8   \n",
      " 3   item_id           int16  \n",
      " 4   item_price        float32\n",
      " 5   item_cnt_day      int16  \n",
      " 6   item_category_id  int8   \n",
      "dtypes: float32(1), int16(2), int8(3), object(1)\n",
      "memory usage: 75.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Feature Distributions\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers removal, getting rid of the outliers & negative values\n",
    "train = train[(train['item_price']<100000) & (train['item_price']>=0)]\n",
    "train = train[(train['item_cnt_day']<1000) & (train['item_cnt_day']>=0)]\n",
    "\n",
    "# Distribution after outliers removal\n",
    "# plot_features = ['item_price','item_cnt_day']\n",
    "# for f in plot_features:\n",
    "#     box_plot(train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num\n",
       "0       59    22154               0\n",
       "1       59     2552               0\n",
       "2       59     2554               0\n",
       "3       59     2555               0\n",
       "4       59     2564               0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Created a dataframe of date_block_num, Store and Item combinations\n",
    "# Created a grid with columns\n",
    "index_cols = ['shop_id','item_id','date_block_num']\n",
    "\n",
    "# For every month we create a grid for all shops & items pair\n",
    "grid = []\n",
    "for block_num in train['date_block_num'].unique():\n",
    "    cur_shops = train.loc[train['date_block_num']==block_num,'shop_id'].unique()\n",
    "    cur_items = train.loc[train['date_block_num']==block_num,'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops,cur_items,[block_num]])),dtype='int32'))\n",
    "grid = pd.DataFrame(np.vstack(grid),columns=index_cols,dtype=np.int32)\n",
    "grid = data_compression(grid)\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10884508 entries, 0 to 10884507\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Dtype\n",
      "---  ------          -----\n",
      " 0   shop_id         int8 \n",
      " 1   item_id         int16\n",
      " 2   date_block_num  int8 \n",
      "dtypes: int16(1), int8(2)\n",
      "memory usage: 41.5 MB\n"
     ]
    }
   ],
   "source": [
    "grid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created Mean Encodings\n",
    "#Group items per month, per shop, per item, sum the sales of the item, mean the price\n",
    "#There is a big difference between np.mean and pandas mean\n",
    "train_m = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day':'sum','item_price':np.mean}).reset_index()\n",
    "train_m = pd.merge(grid,train_m,on=['date_block_num','shop_id','item_id'],how='left').fillna(0)\n",
    "train_m = pd.merge(train_m,items,on='item_id',how='left')\n",
    "train_m = data_compression(train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the mean encoded features\n",
    "for type_id in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    for column_id, aggregator, aggtype in [('item_price',np.mean,'avg'),('item_cnt_day',np.sum,'sum'),('item_cnt_day',np.mean,'avg')]:\n",
    "        mean_df = train.groupby([type_id,'date_block_num']).aggregate(aggregator).reset_index()[[column_id,type_id,'date_block_num']]\n",
    "        mean_df.columns = [type_id+'_'+aggtype+'_'+column_id,type_id,'date_block_num']\n",
    "        train_m = pd.merge(train_m, mean_df, on=['date_block_num',type_id], how='left')\n",
    "        del mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10884508 entries, 0 to 10884507\n",
      "Columns: 15 entries, shop_id to item_category_id_avg_item_cnt_day\n",
      "dtypes: float16(5), float32(2), int16(4), int32(1), int8(3)\n",
      "memory usage: 425.6 MB\n"
     ]
    }
   ],
   "source": [
    "#Fill NaNs\n",
    "for f in train_m.columns:\n",
    "    if 'item_cnt' in f:\n",
    "        train_m[f] = train_m[f].fillna(0)\n",
    "    elif 'item_price' in f:\n",
    "        train_m[f] = train_m[f].fillna(train_m[f].median())\n",
    "\n",
    "# Compress data\n",
    "train_m = data_compression(train_m)\n",
    "train_m.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id_avg_item_price', 'item_id_sum_item_cnt_day',\n",
       "       'item_id_avg_item_cnt_day', 'shop_id_avg_item_price',\n",
       "       'shop_id_sum_item_cnt_day', 'shop_id_avg_item_cnt_day',\n",
       "       'item_category_id_avg_item_price',\n",
       "       'item_category_id_sum_item_cnt_day',\n",
       "       'item_category_id_avg_item_cnt_day'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Created Lag Features\n",
    "#Check the positions of the base lag features\n",
    "train_m.columns.values[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the monthly features, which means the Mean Encoded fatures are all monthly based\n",
    "lag_features = list(train_m.columns[6:])+['item_cnt_day']\n",
    "# The selected months from current month\n",
    "lags = [1,2,3,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag 1 processed\n",
      "lag 2 processed\n",
      "lag 3 processed\n",
      "lag 6 processed\n"
     ]
    }
   ],
   "source": [
    "for lag in lags:\n",
    "    train_new_df = train_m.copy()\n",
    "    # Get the current month\n",
    "    train_new_df['date_block_num'] += lag\n",
    "    train_new_df = train_new_df[['date_block_num','shop_id','item_id']+lag_features]\n",
    "    # Name the columns as lag features of the month\n",
    "    train_new_df.columns = ['date_block_num','shop_id','item_id'] + [x+'_lag_'+str(lag) for x in lag_features]\n",
    "    train_m = pd.merge(train_m,train_new_df,on=['date_block_num','shop_id','item_id'],how='left')\n",
    "    del train_new_df\n",
    "    print ('lag %s processed' %lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10884508 entries, 0 to 10884507\n",
      "Columns: 55 entries, shop_id to item_cnt_day_lag_6\n",
      "dtypes: float16(25), float32(6), int16(16), int32(5), int8(3)\n",
      "memory usage: 1.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs\n",
    "for f in train_m.columns:\n",
    "    if 'item_cnt' in f:\n",
    "        train_m[f] = train_m[f].fillna(0)\n",
    "    elif 'item_price' in f:\n",
    "        train_m[f] = train_m[f].fillna(train_m[f].median())\n",
    "\n",
    "train_m = data_compression(train_m)\n",
    "train_m.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum clip value\n",
    "# Prepare test set\n",
    "max_clip = 30\n",
    "train_m['item_cnt_day'] = train_m['item_cnt_day'].clip(0,max_clip).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag 1 processed\n",
      "lag 2 processed\n",
      "lag 3 processed\n",
      "lag 6 processed\n"
     ]
    }
   ],
   "source": [
    "# Add lag variables\n",
    "for lag in lags:\n",
    "    train_new_df = train_m.copy()\n",
    "    # Get the current month\n",
    "    train_new_df['date_block_num'] += lag\n",
    "    train_new_df = train_new_df[['date_block_num','shop_id','item_id']+lag_features]\n",
    "    # Name the columns as lag features of the month\n",
    "    train_new_df.columns = ['date_block_num','shop_id','item_id'] + [x+'_lag_'+str(lag) for x in lag_features]\n",
    "    test = pd.merge(test,train_new_df,on=['date_block_num','shop_id','item_id'],how='left')\n",
    "    del train_new_df\n",
    "    print ('lag %s processed' %lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs\n",
    "for f in test.columns:\n",
    "    if 'item_cnt' in f:\n",
    "        test[f] = test[f].fillna(0)\n",
    "    elif 'item_price' in f:\n",
    "        test[f] = test[f].fillna(test[f].median())\n",
    "\n",
    "test = data_compression(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop\n",
      "['item_id_avg_item_price', 'item_id_sum_item_cnt_day', 'item_id_avg_item_cnt_day', 'shop_id_avg_item_price', 'shop_id_sum_item_cnt_day', 'shop_id_avg_item_cnt_day', 'item_category_id_avg_item_price', 'item_category_id_sum_item_cnt_day', 'item_category_id_avg_item_cnt_day', 'item_price']\n"
     ]
    }
   ],
   "source": [
    "#Drop all columns which are not lag features\n",
    "cols_to_drop = lag_features[:-1] + ['item_price']\n",
    "print ('Columns to drop')\n",
    "print (cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = train_m.columns.values\n",
    "test_cols = test.columns.values\n",
    "for c in cols_to_drop:\n",
    "    if c in train_cols:\n",
    "        train_m = train_m.drop(c,axis=1)\n",
    "    if c in test_cols:\n",
    "        test = test.drop(c,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new time related features\n",
    "# Month number\n",
    "train_m['month'] = train_m['date_block_num']%12\n",
    "train_m['month'] = train_m['month'].astype(np.int8)\n",
    "# Number of days in a month, no leap years here\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "train_m['days'] = train_m['month'].map(days).astype(np.int8)\n",
    "\n",
    "test['month'] = 11\n",
    "test['month'] = test['month'].astype(np.int8)\n",
    "test['days'] = 30\n",
    "test['days'] = test['days'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_cnt_day'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if lag variables in test set are correct\n",
    "#Assert all the columns are the same except target column\n",
    "set(train_m.columns.values) ^ set(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_id_avg_item_price_lag_1</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_avg_item_price_lag_1</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_6</th>\n",
       "      <th>shop_id_avg_item_price_lag_6</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_6</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_6</th>\n",
       "      <th>item_category_id_avg_item_price_lag_6</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_6</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_6</th>\n",
       "      <th>item_cnt_day_lag_6</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  item_cnt_day  item_category_id  \\\n",
       "0       59    22154               0           1.0                37   \n",
       "1       59     2552               0           0.0                58   \n",
       "2       59     2554               0           0.0                58   \n",
       "3       59     2555               0           0.0                56   \n",
       "4       59     2564               0           0.0                59   \n",
       "\n",
       "   item_id_avg_item_price_lag_1  item_id_sum_item_cnt_day_lag_1  \\\n",
       "0                         299.0                               0   \n",
       "1                         299.0                               0   \n",
       "2                         299.0                               0   \n",
       "3                         299.0                               0   \n",
       "4                         299.0                               0   \n",
       "\n",
       "   item_id_avg_item_cnt_day_lag_1  shop_id_avg_item_price_lag_1  \\\n",
       "0                             0.0                         879.0   \n",
       "1                             0.0                         879.0   \n",
       "2                             0.0                         879.0   \n",
       "3                             0.0                         879.0   \n",
       "4                             0.0                         879.0   \n",
       "\n",
       "   shop_id_sum_item_cnt_day_lag_1  ...  item_id_avg_item_cnt_day_lag_6  \\\n",
       "0                               0  ...                             0.0   \n",
       "1                               0  ...                             0.0   \n",
       "2                               0  ...                             0.0   \n",
       "3                               0  ...                             0.0   \n",
       "4                               0  ...                             0.0   \n",
       "\n",
       "   shop_id_avg_item_price_lag_6  shop_id_sum_item_cnt_day_lag_6  \\\n",
       "0                         847.0                               0   \n",
       "1                         847.0                               0   \n",
       "2                         847.0                               0   \n",
       "3                         847.0                               0   \n",
       "4                         847.0                               0   \n",
       "\n",
       "   shop_id_avg_item_cnt_day_lag_6  item_category_id_avg_item_price_lag_6  \\\n",
       "0                             0.0                                  376.0   \n",
       "1                             0.0                                  376.0   \n",
       "2                             0.0                                  376.0   \n",
       "3                             0.0                                  376.0   \n",
       "4                             0.0                                  376.0   \n",
       "\n",
       "   item_category_id_sum_item_cnt_day_lag_6  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   item_category_id_avg_item_cnt_day_lag_6  item_cnt_day_lag_6  month  days  \n",
       "0                                      0.0                   0      0    31  \n",
       "1                                      0.0                   0      0    31  \n",
       "2                                      0.0                   0      0    31  \n",
       "3                                      0.0                   0      0    31  \n",
       "4                                      0.0                   0      0    31  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_id_avg_item_price_lag_1</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_avg_item_price_lag_1</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_6</th>\n",
       "      <th>shop_id_avg_item_price_lag_6</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_6</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_6</th>\n",
       "      <th>item_category_id_avg_item_price_lag_6</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_6</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_6</th>\n",
       "      <th>item_cnt_day_lag_6</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>3407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>3407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>1190.137939</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  item_category_id  \\\n",
       "0        5     5037              34                19   \n",
       "1        5     5320              34                55   \n",
       "2        5     5233              34                19   \n",
       "3        5     5232              34                23   \n",
       "4        5     5268              34                20   \n",
       "\n",
       "   item_id_avg_item_price_lag_1  item_id_sum_item_cnt_day_lag_1  \\\n",
       "0                   1499.000000                              25   \n",
       "1                    449.000000                               0   \n",
       "2                   1199.000000                              42   \n",
       "3                   1190.137939                              29   \n",
       "4                    449.000000                               0   \n",
       "\n",
       "   item_id_avg_item_cnt_day_lag_1  shop_id_avg_item_price_lag_1  \\\n",
       "0                             1.0                        1028.0   \n",
       "1                             0.0                        1240.0   \n",
       "2                             1.0                        1028.0   \n",
       "3                             1.0                        1028.0   \n",
       "4                             0.0                        1240.0   \n",
       "\n",
       "   shop_id_sum_item_cnt_day_lag_1  shop_id_avg_item_cnt_day_lag_1  ...  \\\n",
       "0                            1054                             1.0  ...   \n",
       "1                               0                             0.0  ...   \n",
       "2                            1054                             1.0  ...   \n",
       "3                            1054                             1.0  ...   \n",
       "4                               0                             0.0  ...   \n",
       "\n",
       "   item_id_avg_item_cnt_day_lag_6  shop_id_avg_item_price_lag_6  \\\n",
       "0                             1.0                         959.0   \n",
       "1                             0.0                        1099.0   \n",
       "2                             1.0                         959.0   \n",
       "3                             0.0                        1099.0   \n",
       "4                             0.0                        1099.0   \n",
       "\n",
       "   shop_id_sum_item_cnt_day_lag_6  shop_id_avg_item_cnt_day_lag_6  \\\n",
       "0                            1013                             1.0   \n",
       "1                               0                             0.0   \n",
       "2                            1013                             1.0   \n",
       "3                               0                             0.0   \n",
       "4                               0                             0.0   \n",
       "\n",
       "   item_category_id_avg_item_price_lag_6  \\\n",
       "0                                 1418.0   \n",
       "1                                  559.0   \n",
       "2                                 1418.0   \n",
       "3                                  559.0   \n",
       "4                                  559.0   \n",
       "\n",
       "   item_category_id_sum_item_cnt_day_lag_6  \\\n",
       "0                                     3407   \n",
       "1                                        0   \n",
       "2                                     3407   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   item_category_id_avg_item_cnt_day_lag_6  item_cnt_day_lag_6  month  days  \n",
       "0                                      1.0                   1     11    30  \n",
       "1                                      0.0                   0     11    30  \n",
       "2                                      1.0                   3     11    30  \n",
       "3                                      0.0                   0     11    30  \n",
       "4                                      0.0                   0     11    30  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the order of the columns are the same for train & test.<br>\n",
    "(Except for the target column 'item_cnt_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-6a07cdffcad7>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 33]['item_cnt_day'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10820113    0.0\n",
      "Name: item_cnt_day, dtype: float16\n",
      "10581628    1.0\n",
      "Name: item_cnt_day, dtype: float16\n",
      "10372045    3.0\n",
      "Name: item_cnt_day, dtype: float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-6a07cdffcad7>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 33]['item_cnt_day'])\n",
      "<ipython-input-107-6a07cdffcad7>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 32]['item_cnt_day'])\n",
      "<ipython-input-107-6a07cdffcad7>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 32]['item_cnt_day'])\n",
      "<ipython-input-107-6a07cdffcad7>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 31]['item_cnt_day'])\n",
      "<ipython-input-107-6a07cdffcad7>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 31]['item_cnt_day'])\n"
     ]
    }
   ],
   "source": [
    "print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 33]['item_cnt_day'])\n",
    "print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 32]['item_cnt_day'])\n",
    "print(train_m[train_m['shop_id'] == 5][train_m['item_id'] == 5037][train_m['date_block_num'] == 31]['item_cnt_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lagged value for (5\t5037) actually correspond, looks like we dont have bugs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the recent bit of data\n",
    "train_m = train_m[train_m['date_block_num']>12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train & validation\n",
    "train_set = train_m[train_m['date_block_num']<33]\n",
    "val_set = train_m[train_m['date_block_num']==33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5820464, 47)\n",
      "(238084, 47)\n",
      "(214200, 46)\n"
     ]
    }
   ],
   "source": [
    "print (train_set.shape)\n",
    "print (val_set.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5820464, 46)\n",
      "(5820464,)\n",
      "(238084, 46)\n",
      "(238084,)\n",
      "(214200, 46)\n"
     ]
    }
   ],
   "source": [
    "#Modelling\n",
    "\n",
    "# Ridge Regression (Linear)\n",
    "# xgboost (Tree based)\n",
    "# Random Forest (Tree based)\n",
    "# ARIMA\n",
    "\n",
    "#Data Prep\n",
    "\n",
    "# divide data into x & y\n",
    "train_x = train_set.drop(['item_cnt_day'],axis=1)\n",
    "train_y = train_set['item_cnt_day']\n",
    "val_x = val_set.drop(['item_cnt_day'],axis=1)\n",
    "val_y = val_set['item_cnt_day']\n",
    "\n",
    "features = list(train_x.columns.values)\n",
    "\n",
    "# Check if the data sets have equal amount of features\n",
    "print (train_x.shape)\n",
    "print (train_y.shape)\n",
    "print (val_x.shape)\n",
    "print (val_y.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_set\n",
    "del val_set\n",
    "\n",
    "\n",
    "#For saving data & output results/models\n",
    "def post_processing(model,model_name,train_x,val_x,test_x,train_y,val_y,test):\n",
    "    # Here we once again clip the output to 0~20\n",
    "    train_pred = model.predict(train_x).clip(0, 20)\n",
    "    val_pred = model.predict(val_x).clip(0, 20)\n",
    "    test_pred = model.predict(test_x).clip(0, 20)\n",
    "\n",
    "    #Get rmse scores\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_y, train_pred))\n",
    "    print(\"Train RMSE: %f\" % (train_rmse))\n",
    "    val_rmse = np.sqrt(mean_squared_error(val_y, val_pred))\n",
    "    print(\"Val RMSE: %f\" % (val_rmse))\n",
    "    \n",
    "    #Export submission\n",
    "    submission = pd.DataFrame({'ID':test.index,'item_cnt_month': test_pred})\n",
    "    submission.to_csv('%s_submission.csv'%model_name,index=False)\n",
    "\n",
    "    #save model to file\n",
    "    return train_pred,val_pred,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting feature importance\n",
    "def plot_feature_importances(importances,indices,features,title,dimensions):\n",
    "    plt.figure(figsize=dimensions)\n",
    "    plt.title(title)\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "# Normalise data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_x.values)\n",
    "train_x_norm = scaler.transform(train_x.values)\n",
    "val_x_norm = scaler.transform(val_x.values)\n",
    "test_norm = scaler.transform(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.572704792022705\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "ts = time.time()\n",
    "# Training\n",
    "lm = linear_model.Ridge()\n",
    "lm.fit(train_x_norm,train_y)\n",
    "print ('Training time: %s' %(time.time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1.153216\n",
      "Val RMSE: 1.169679\n"
     ]
    }
   ],
   "source": [
    "# Performance and test predictions\n",
    "train_pred1,val_pred1,test_pred1 = post_processing(lm,'ridge',train_x_norm,val_x_norm,test_norm,train_y,val_y,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train_x_norm\n",
    "#del val_x_norm\n",
    "#del test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#XGboost\n",
    "\n",
    "\n",
    "ts = time.time()\n",
    "xgbtrain = xgb.DMatrix(train_x.values, train_y.values)\n",
    "\n",
    "param = {'max_depth':8, \n",
    "         'subsample':1,\n",
    "         'min_child_weight':0.5,\n",
    "         'eta':0.3, \n",
    "         'num_round':1000, \n",
    "         'seed':1,\n",
    "         'verbosity':2,\n",
    "         'eval_metric':'rmse'} # random parameters\n",
    "\n",
    "bst = xgb.train(param, xgbtrain)\n",
    "print ('Training time: %s' %(time.time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Performance and test predictions\n",
    "train_pred2,val_pred2,test_pred2 = post_processing(bst,'xgboost',xgb.DMatrix(train_x.values),xgb.DMatrix(val_x.values),xgb.DMatrix(test.values),train_y,val_y,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "#Use the same examples as above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA\n",
    "\n",
    "from statsmodels.tsa.statespace import sarimax as smt\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf \n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-3c4ebaba5384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date_block_num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"item_cnt_day\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales' is not defined"
     ]
    }
   ],
   "source": [
    "ts = sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "new_ts = difference(ts, 12)\n",
    "\n",
    "\n",
    "def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style):    \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n",
    "        layout = (3, 2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "        qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "        pp_ax = plt.subplot2grid(layout, (2, 1))\n",
    "        \n",
    "        y.plot(ax=ts_ax)\n",
    "        ts_ax.set_title(title)\n",
    "        statsmodels.graphics.tsaplots.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n",
    "        statsmodels.graphics.tsaplots.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n",
    "        smt.qqplot(y, line='s', ax=qq_ax)\n",
    "        qq_ax.set_title('QQ Plot')        \n",
    "        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    return \n",
    "\n",
    "max_lag = 12\n",
    "_ = tsplot(ts.values, lags=max_lag,title=\"My De-trend and De-seasonalized values process\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-8af6c5498aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ARMA, First create a multi-index dataframe with (\"date_block_num\", \"shop_id\", \"item_id\") as index in order to easily find the number of time an item_id was sold at month date_block_num.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sales_monthly = sales.groupby(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"date_block_num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shop_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item_price\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                               \"item_cnt_day\"].agg({\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales' is not defined"
     ]
    }
   ],
   "source": [
    "#ARMA, First create a multi-index dataframe with (\"date_block_num\", \"shop_id\", \"item_id\") as index in order to easily find the number of time an item_id was sold at month date_block_num.\n",
    "\n",
    "sales_monthly = sales.groupby(\n",
    "    [\"date_block_num\", \"shop_id\", \"item_id\"])[\"date\", \"item_price\",\n",
    "                                              \"item_cnt_day\"].agg({\n",
    "    \"date\": [\"min\", \"max\"],\n",
    "    \"item_price\": \"mean\",\n",
    "    \"item_cnt_day\": \"sum\"})\n",
    "\n",
    "#Each \"shop_id\", \"item_id\" is a time series for which we will find and create a SARIMAX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting SARIMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "array = []\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "   \n",
    "    try:\n",
    "        # We get all the dates/indexes in order to fill the blanks of the time series with 0s later on \n",
    "        # We have a KeyError issue at row['shop_id']:  5  row['item_id']:  5003 which I don't have in my local notebook\n",
    "        existing_indexes = [x[0] \n",
    "                            for x in sales_monthly.loc[pd.IndexSlice[:, \n",
    "                            [row['shop_id']], [row['item_id']]], :].index]\n",
    "        # We multiply the price of the item by the number of this kind of item sold\n",
    "        ts = pd.DataFrame(sales_monthly.loc[pd.IndexSlice[:, # We have a key error here\n",
    "                      [row['shop_id']], [row['item_id']]], :]['item_price'].values *\n",
    "                      sales_monthly.loc[pd.IndexSlice[:, \n",
    "                      [row['shop_id']], [row['item_id']]], :]['item_cnt_day'].values).T.iloc[0]\n",
    "        ts_values = list(ts.values)\n",
    "        if ts.values != [] and len(ts.values) > 4:\n",
    "          # if this item isn't sold every month, we need to fill the gaps in the \n",
    "          # sellings list\n",
    "            if len(ts.values<3):\n",
    "                all_indexes = list(range(33))\n",
    "                insert_at_indexes = set(all_indexes) - set(existing_indexes)\n",
    "                insert_at_indexes = [list(group) \n",
    "                            for group in mit.consecutive_groups(insert_at_indexes)][1:]\n",
    "                insert_at_indexes = [item for sublist in insert_at_indexes for item in sublist]\n",
    "                # we only take the last one \n",
    "                for insert_at in insert_at_indexes:\n",
    "                      ts_values[insert_at:insert_at] = [0.]\n",
    "            best_aic = np.inf\n",
    "            best_order = None\n",
    "            best_model = None\n",
    "\n",
    "          # we need to test different orders, but let's have a go with that ...\n",
    "          ranges = range(1, 5)\n",
    "            for difference in ranges:\n",
    "                tmp_model = SARIMAX(ts_values, order=(0, 1, 0), trend='t').fit()\n",
    "                tmp_aic = tmp_model.aic\n",
    "                if tmp_aic < best_aic:\n",
    "                        best_aic = tmp_aic\n",
    "                        best_difference = difference\n",
    "                        best_model = tmp_model\n",
    "            if best_model is not None:\n",
    "                y_hat = best_model.forecast()[0]\n",
    "                if y_hat < 0:\n",
    "                    y_hat = 0.5\n",
    "            else:\n",
    "                y_hat = 0.5\n",
    "        else:\n",
    "            y_hat = 0.5\n",
    "    except KeyError:\n",
    "        y_hat = 0.5\n",
    "    d = {'id': row['ID'], 'item_cnt_month': y_hat}\n",
    "    array.append(d)\n",
    "\n",
    "df = pd.DataFrame(array)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.55.tar.gz (23 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from yfinance) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from yfinance) (1.19.2)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from yfinance) (2.24.0)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.9.tar.gz (8.1 kB)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from yfinance) (4.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24->yfinance) (2020.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->yfinance) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->yfinance) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jiguzmans/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Building wheels for collected packages: yfinance, multitasking\n",
      "  Building wheel for yfinance (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22618 sha256=4baa986e851159a28266df463c2111cc2588faa6ad837dea5fc83934696ca6a2\n",
      "  Stored in directory: /Users/jiguzmans/Library/Caches/pip/wheels/b4/c3/39/9c01ae2b4726f37024bba5592bec868b47a2fab5a786e8979a\n",
      "  Building wheel for multitasking (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.9-py3-none-any.whl size=8367 sha256=9bccd1a754182fef1476674829db390e19b8b395b2a443d917106287c7871de1\n",
      "  Stored in directory: /Users/jiguzmans/Library/Caches/pip/wheels/57/6d/a3/a39b839cc75274d2acfb1c58bfead2f726c6577fe8c4723f13\n",
      "Successfully built yfinance multitasking\n",
      "Installing collected packages: multitasking, yfinance\n",
      "Successfully installed multitasking-0.0.9 yfinance-0.1.55\n"
     ]
    }
   ],
   "source": [
    "! pip install yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "\n",
    "# get historical market data\n",
    "hist = msft.history(period=\"5y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2020-10-01    211.418289\n",
       "2020-11-01    201.477280\n",
       "2020-12-01    215.713181\n",
       "2021-01-01    221.908905\n",
       "2021-02-01    239.099304\n",
       "Freq: MS, Name: Close, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_settle = hist['Close'].resample('MS').ffill().dropna()\n",
    "df_settle.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF result 2.325921140144809\n",
      "p-value =  0.9989710666347107\n",
      "critical values (1%): -3.563\n",
      "critical values (5%): -2.919\n",
      "critical values (10%): -2.597\n"
     ]
    }
   ],
   "source": [
    "#Here, the p-value is larger than 0.05, meaning the we cannot reject the null hypothesis stating that the time series \n",
    "#is non-stationary. Therefore, we must apply some transformation and some differencing to remove the trend and remove \n",
    "#the change in variance.\n",
    "#Finding model parameters by grid search\n",
    "#We could try to find the model parameters by detrending with a log-difference np.log(df_settle) and differenciating \n",
    "#df_settle.diff(seasonality) and then run the Augmented Dickey-Fuller test again to see if we have a stationary time series.\n",
    "#Although these plots can give us a rough idea of the processes in play, it is better to test multiple scenarios \n",
    "#and choose the model that yield the lowest AIC.\n",
    "#Therefore grid searching (p, d, q, s), allows to feed the data as it is without any transformation \n",
    "#since SARIMAX will do the transformation for you under the hood.\n",
    "\n",
    "'We just need to find the model minimizing the AIC'\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(df_settle)\n",
    "print('ADF result', result[0])\n",
    "print('p-value = ', result[1])\n",
    "\n",
    "critical_values = result[4]\n",
    "\n",
    "for key, value, in critical_values.items():\n",
    "    print(\"critical values (%s): %.3f\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected unindent (<ipython-input-138-60421f11cb4e>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-138-60421f11cb4e>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    if not lowest_aic or model_result.aic < lowest_aic:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected unindent\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# from statsmodels.api.tsa.statespace import SARIMAX\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def arima_grid_search(dataframe, s):\n",
    "    p = d = q = range(2)\n",
    "    param_combinations = list(itertools.product(p, d, q))\n",
    "\n",
    "    lowest_aic, pdq, pdqs = None, None, None\n",
    "\n",
    "    total_iterations = 0\n",
    "    for order in param_combinations:\n",
    "        for (p, d, q) in param_combinations:\n",
    "            seasonal_order = (p, d, q, s)\n",
    "            total_iterations +=1\n",
    "            try:\n",
    "                model = SARIMAX(df_settle, order=order,\n",
    "                                seasonal_order = seasonal_order,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False,\n",
    "                                disp=False\n",
    "                              )\n",
    "                model_result = model.fit(maxiter=200, disp=False)\n",
    "\n",
    "            if not lowest_aic or model_result.aic < lowest_aic:\n",
    "            lowest_aic = model_result.aic\n",
    "            pdq, pdqs = order, seasonal_order\n",
    "\n",
    "    except Exception as ex:\n",
    "            continue\n",
    "\n",
    "    return lowest_aic, pdq, pdqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_aic, order, seasonal_order = arima_grid_search(df_settle, 12)\n",
    "print('ARIMA{}x{}'.format(order, seasonal_order))\n",
    "print('Lowest AIC: %.3f' % (lowest_aic))\n",
    "\n",
    "#Therefore, this suggests are ARIMA model with an AR(1) process and a MA(0).\n",
    "#The order of differencing (d) process is 1. But it's not related to the AIC, it has been found by the grid search \n",
    "#model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SARIMAX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-664e5e5e4692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fitting SARIMAX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = SARIMAX(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf_settle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseasonal_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseasonal_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SARIMAX' is not defined"
     ]
    }
   ],
   "source": [
    "#fitting SARIMAX\n",
    "model = SARIMAX(\n",
    "    df_settle, \n",
    "    order=order,\n",
    "    seasonal_order = seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False,\n",
    "    disp=False\n",
    ")\n",
    "\n",
    "model_results = model.fit(maxiter=200, disp=False)\n",
    "\n",
    "print(model_results.summary())\n",
    "\n",
    "model_results.plot_diagnostics(figsize=(12,8));\n",
    "\n",
    "model_results.resid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the normal Q-Q plot, we can see that we almost have a straight line, which suggest no systematic departure from normality. Also, the correlogram on the bottom right suggests that there is no autocorrelation in the residuals, and so they are effectively white noise.\n",
    "\n",
    "Predicting the model - We are ready to plot the predictions of our model and forecast into the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_settle.index)\n",
    "prediction = model_results.get_prediction(\n",
    "    start=n-14*5, #changed from 12\n",
    "    end=n+5\n",
    ")\n",
    "\n",
    "prediction_ci = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ci.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = df_settle['2008':].plot(label='actual')\n",
    "prediction_ci.plot(\n",
    "    ax=ax, style=['--', '--'],\n",
    "    label='predicted/forecasted')\n",
    "\n",
    "ci_index = prediction_ci.index\n",
    "lower_ci = prediction_ci.iloc[:, 0]\n",
    "upper_ci = prediction_ci.iloc[:, 1]\n",
    "\n",
    "ax.fill_between(ci_index, lower_ci, upper_ci,\n",
    "                color='r', alpha= .1)\n",
    "\n",
    "ax.set_xlabel('Time (years)')\n",
    "ax.set_ylabel('Prices')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-469d8ab6d26b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#formating dates as a date object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%d.%m.%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales' is not defined"
     ]
    }
   ],
   "source": [
    "#formating dates as a date object\n",
    "sales.date = sales.date.apply(lambda x: datetime.datetime.strptime(x, \"%d.%m.%Y\"))\n",
    "# check\n",
    "print(sales.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we have ~2M sales of items in the period we were given.\n",
    "# How do they look like?\n",
    "sales_monthly = sales.groupby(\n",
    "    [\"date_block_num\", \"shop_id\", \"item_id\"])[\"date\",\"item_price\",\n",
    "                                              \"item_cnt_day\"].agg({\n",
    "        \"date\":[\"min\",\"max\"],\n",
    "        \"item_price\":\"mean\",\n",
    "        \"item_cnt_day\":\"sum\"})\n",
    "\n",
    "sales_monthly.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of items per cat \n",
    "items.head()\n",
    "x = items.groupby(['item_category_id']).count() # but count is in column item_id ?\n",
    "x = x.sort_values(by='item_id',ascending=False)\n",
    "x=x.iloc[0:10].reset_index()\n",
    "x\n",
    "# plot\n",
    "plt.figure(figsize=(8,4))\n",
    "ax=sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\n",
    "plt.title(\"Items per Category\")\n",
    "plt.ylabel(\"# of items\", fontsize=12)\n",
    "plt.xlabel(\"Category\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-132-d653374fa793>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-132-d653374fa793>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    The sales by category seem to be unbalanced.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The sales by category seem to be unbalanced.\n",
    "\n",
    "First let's compute the total sales per month and plot that data.\n",
    "\n",
    "ts = sales.groupby(['date_block_num'])['item_cnt_day'].sum()\n",
    "# ts = sales.groupby(['date_block_num','shop_id'])['item_cnt_day'].sum()\n",
    "\n",
    "\n",
    "out = sales.pivot_table(index='shop_id', \n",
    "                        columns='date_block_num',\n",
    "                        values='item_cnt_day',\n",
    "                        aggfunc='sum')\n",
    "out = out.fillna(out.mean())\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(ts)\n",
    "plt.title(\"Total sales of the company\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"# sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for i,row in out.iterrows():\n",
    "    plt.scatter(out.columns, row)\n",
    "plt.title(\"Total sales of the company\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"# sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(ts.rolling(window=12,center=False).mean(), label = \"rolling mean\")\n",
    "plt.plot(ts.rolling(window=12, center=False).std(), label = \"rolling std\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-cd58434de70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseasonal_decompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multiplicative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseasonal_decompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"addidtive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "res = sm.tsa.seasonal_decompose(ts.values, freq=12, model=\"multiplicative\")\n",
    "fig=res.plot()\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(ts.values, freq=12, model=\"addidtive\")\n",
    "fig=res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-e62ea82d284a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date_block_num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"item_cnt_day\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales' is not defined"
     ]
    }
   ],
   "source": [
    "#Now I need to predict at the (shop,item_level)\n",
    "\n",
    "import statsmodels.api as smt\n",
    "import statsmodels\n",
    "import scipy.stats as scs\n",
    "from pandas import Series\n",
    "\n",
    "ts = sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "new_ts = difference(ts, 12)\n",
    "\n",
    "\n",
    "def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style):    \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n",
    "        layout = (3, 2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "        qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "        pp_ax = plt.subplot2grid(layout, (2, 1))\n",
    "        \n",
    "        y.plot(ax=ts_ax)\n",
    "        ts_ax.set_title(title)\n",
    "        statsmodels.graphics.tsaplots.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n",
    "        statsmodels.graphics.tsaplots.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n",
    "        smt.qqplot(y, line='s', ax=qq_ax)\n",
    "        qq_ax.set_title('QQ Plot')        \n",
    "        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    return \n",
    "\n",
    "max_lag = 12\n",
    "_ = tsplot(ts.values, lags=max_lag,title=\"My De-trend and De-seasonalized values process\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA: We are now going to buil our model to predict the future sales for the company.\n",
    "\n",
    "We first need to create a multi-index dataframe with (\"date_block_num\", \"shop_id\", \"item_id\") as index in order to easily find the number of time an item_id was sold at month date_block_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly = sales.groupby(\n",
    "    [\"date_block_num\", \"shop_id\", \"item_id\"])[\"date\", \"item_price\",\n",
    "                                              \"item_cnt_day\"].agg({\n",
    "    \"date\": [\"min\", \"max\"],\n",
    "    \"item_price\": \"mean\",\n",
    "    \"item_cnt_day\": \"sum\"})\n",
    "\n",
    "sales_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each \"shop_id\", \"item_id\" is a time series for which we will find and create a SARIMAX model.\n",
    "\n",
    "We now find these couples iterating through test and creating the related SARIMAX model if we have enough data (at least 33 month of sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting SARIMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "array = []\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "   \n",
    "    try:\n",
    "        # We get all the dates/indexes in order to fill the blanks of the time series with 0s later on \n",
    "        # We have a KeyError issue at row['shop_id']:  5  row['item_id']:  5003 which I don't have in my local notebook\n",
    "        existing_indexes = [x[0] \n",
    "                            for x in sales_monthly.loc[pd.IndexSlice[:, \n",
    "                            [row['shop_id']], [row['item_id']]], :].index]\n",
    "        # We multiply the price of the item by the number of this kind of item sold\n",
    "        ts = pd.DataFrame(sales_monthly.loc[pd.IndexSlice[:, # We have a key error here\n",
    "                      [row['shop_id']], [row['item_id']]], :]['item_price'].values *\n",
    "                      sales_monthly.loc[pd.IndexSlice[:, \n",
    "                      [row['shop_id']], [row['item_id']]], :]['item_cnt_day'].values).T.iloc[0]\n",
    "        ts_values = list(ts.values)\n",
    "        if ts.values != [] and len(ts.values) > 4:\n",
    "          # if this item isn't sold every month, we need to fill the gaps in the \n",
    "          # sellings list\n",
    "            if len(ts.values<3):\n",
    "                all_indexes = list(range(33))\n",
    "                insert_at_indexes = set(all_indexes) - set(existing_indexes)\n",
    "                insert_at_indexes = [list(group) \n",
    "                            for group in mit.consecutive_groups(insert_at_indexes)][1:]\n",
    "                insert_at_indexes = [item for sublist in insert_at_indexes for item in sublist]\n",
    "                # we only take the last one \n",
    "                for insert_at in insert_at_indexes:\n",
    "                      ts_values[insert_at:insert_at] = [0.]\n",
    "            best_aic = np.inf\n",
    "            best_order = None\n",
    "            best_model = None\n",
    "\n",
    "          # we need to test different orders, but let's have a go with that ...\n",
    "          ranges = range(1, 5)\n",
    "            for difference in ranges:\n",
    "                tmp_model = SARIMAX(ts_values, order=(0, 1, 0), trend='t').fit()\n",
    "                tmp_aic = tmp_model.aic\n",
    "                if tmp_aic < best_aic:\n",
    "                        best_aic = tmp_aic\n",
    "                        best_difference = difference\n",
    "                        best_model = tmp_model\n",
    "            if best_model is not None:\n",
    "                y_hat = best_model.forecast()[0]\n",
    "                if y_hat < 0:\n",
    "                    y_hat = 0.5\n",
    "            else:\n",
    "                y_hat = 0.5\n",
    "        else:\n",
    "            y_hat = 0.5\n",
    "    except KeyError:\n",
    "        y_hat = 0.5\n",
    "    d = {'id': row['ID'], 'item_cnt_month': y_hat}\n",
    "    array.append(d)\n",
    "\n",
    "df = pd.DataFrame(array)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try LSTM RNNs too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
